{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are a helpful AI assistant that makes stories by completing the query provided by the user\n",
      "Once upon a time in 1947 \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There were just a few thousand people on earth.\n",
      "The question was, how many have lived to see the day that humanity has spread to such a big place?\n",
      "The answer is... about the same number that have died.\n",
      "The only difference was that they were not allowed to know it.\n",
      "So it was an interesting question to ask some of them...\n",
      "One of the researchers at that time was Dr. Henry Ford Jr.\n",
      "To answer this question, he wrote a book called \"The Miracle at Ford's Theater\".\n",
      "When the book came out, the technology was still on a par with it.\n",
      "It was still capable of providing answers to very complex and complex questions.\n",
      "He explained it in a very humorous way.\n",
      "\"The thing is, these people, they don't understand it, they simply tell you how it works. They tell you how it's done.\n",
      "They don't know that they're doing it.\n",
      "They have no idea that they're doing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt the user to enter the Hugging Face Hub API token securely\n",
    "huggingfacehub_api_token = getpass(\"Enter your Hugging Face Hub API token: \")\n",
    "\n",
    "# Set the environment variable with the entered token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = huggingfacehub_api_token\n",
    "\n",
    "model_id = \"gpt2-medium\"\n",
    "conv_model = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    "    repo_id=model_id,\n",
    "    model_kwargs={\"temperature\": 0.8, \"max_new_tokens\": 200}\n",
    ")\n",
    "\n",
    "template = \"\"\" You are a helpful AI assistant that makes stories by completing the query provided by the user\n",
    "{query} \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['query'])\n",
    "\n",
    "conv_chain = LLMChain(llm=conv_model, prompt=prompt, verbose=True)\n",
    "\n",
    "print(conv_chain.run(\"Once upon a time in 1947\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GathererImmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
