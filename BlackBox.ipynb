{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for HuggingFacePipeline\napi_token\n  extra fields not permitted (type=value_error.extra)\nmodel\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Hugging Face components\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFacePipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHUGGINGFACEHUB_API_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Define intents, entities, and agents\u001b[39;00m\n\u001b[0;32m     23\u001b[0m intents \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_suggestion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_explanation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocumentation_lookup\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\load\\serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for HuggingFacePipeline\napi_token\n  extra fields not permitted (type=value_error.extra)\nmodel\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os \n",
    "\n",
    "def read_token_from_file(file_path=\"Token.env\"):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = read_token_from_file(\"Token.env\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "# Load Hugging Face model and tokenizer\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set up Hugging Face components\n",
    "pipeline = HuggingFacePipeline(model=model_name, api_token=HUGGINGFACEHUB_API_TOKEN)\n",
    "\n",
    "# Define intents, entities, and agents\n",
    "intents = [\"code_suggestion\", \"error_explanation\", \"documentation_lookup\"]\n",
    "entities = [\"code_snippet\", \"error_message\", \"api_name\"]\n",
    "\n",
    "@Tool\n",
    "def code_suggestion_agent(prompt):\n",
    "    completions = pipeline(prompt)\n",
    "    return completions\n",
    "\n",
    "@Tool\n",
    "def error_explanation_agent(error_message):\n",
    "    explanation = pipeline(f\"Explain this error: {error_message}\")\n",
    "    return explanation\n",
    "\n",
    "@Tool\n",
    "def documentation_agent(api_name):\n",
    "    docs = pipeline(f\"Find documentation for {api_name}\")\n",
    "    return docs\n",
    "\n",
    "# Register agents\n",
    "manager = HuggingFaceHub()\n",
    "manager.register_tool(code_suggestion_agent, intents=[\"code_suggestion\"])\n",
    "manager.register_tool(error_explanation_agent, intents=[\"error_explanation\"])\n",
    "manager.register_tool(documentation_agent, intents=[\"documentation_lookup\"])\n",
    "\n",
    "# Conversation loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    intent, entities = manager.classify_intent(user_input)\n",
    "    response = manager.execute(intent, entities)\n",
    "    print(\"Chatbot: \", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GathererImmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
